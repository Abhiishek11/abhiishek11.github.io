@inproceedings{karwankar2025ucue,
  author       = {Abhishek Karwankar and Elise Ruggiero and Zoe Lipkin and Malika Karthik Iyer and Simon Brugel and Prerana Khatiwada and Daniel Stevens and Matthew Louis Mauriello},
  title        = {uCue: An Interactive Musical Interface to Enhance Formative Listening Experiences for Children with ASD},
  booktitle    = {Proceedings of the 2025 ACM Interaction Design and Children Conference (IDC '25)},
  year         = {2025},
  month        = {June},
  pages        = {18},
  address      = {Reykjavik, Iceland},
  publisher    = {ACM},
  location     = {Reykjavik, Iceland},
  doi          = {10.1145/3713043.3727053},
  url          = {https://doi.org/10.1145/3713043.3727053},
  selected     = true,
  preview      = {ucue.png},
  pdf          = {idc25-3.pdf}

}

@article{Wang_Erqsous_Khatiwada_Karwankar_Alhassan_Chandrasekaran_Abraham_Lovell_Ngo_Mauriello_2025, 
title={Leveraging Large Language Models for Review Classification and Rating Estimation of Mental Health Applications}, 
volume={19}, url={https://ojs.aaai.org/index.php/ICWSM/article/view/35916}, 
DOI={10.1609/icwsm.v19i1.35916}, 
abstractNote={Large Language Models (LLMs) can analyze large datasets semantically. However, research on applying LLMs for mental health text classification is relatively new and developing. Existing methods often use supervised, deep, and reinforcement learning, which rely heavily on fine-tuning and reward models. To investigate whether LLMs can assist in recommending mental health apps based on user reviews, our study collected approximately 200k user reviews from 73 mental health mobile applications. We instructed selected LLMs to classify individual reviews into 1-5 star ratings, subsequently averaging these results to derive an overall rating for each app reflecting current user feedback. While the best supervised learning method in our experiments achieved an F1-Score of 0.79 which required significantly more human effort, the GPT-4 and Gemini 1.5 Pro delivered a strong ‘out-of-the-box’ performance with an overall F1-Score of 0.76. We provide further statistical comparisons and discussions of the performance of these models for the text classification task. Using a crowdsourcing platform to determine agreement levels, we observed that human ratings align closely with GPT ratings. In addition, we analyze specific features and concerns highlighted in mental health app reviews. Alongside our analysis, we make our data available for further experimentation and benchmarking.}, 
number={1}, 
journal={Proceedings of the International AAAI Conference on Web and Social Media}, 
author={Wang, Qile and Erqsous, Moath and Khatiwada, Prerana and Karwankar, Abhishek and Alhassan, Fatimah Mohammad and Chandrasekaran, Aishwarya and Abraham, Benita and Lovell, Faith and Ngo, Andrew Anh and Mauriello, Matthew Louis}, 
year={2025}, 
month={Jun.}, 
pages={2017-2029},
pdf={ICWSM2025.pdf},
preview={mhard.png}
}
